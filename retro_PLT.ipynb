{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a78cd4-b1d7-4c58-98aa-6c3477bbe48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "pd.options.mode.chained_assignment = None \n",
    "from statistics import mean\n",
    "from Profile_Generation import *\n",
    "from plotting import *\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.patches as patches\n",
    "from scipy.optimize import curve_fit\n",
    "from openpyxl import load_workbook\n",
    "import math\n",
    "from scipy.optimize import OptimizeWarning\n",
    "warnings.simplefilter(\"ignore\", OptimizeWarning)\n",
    "import timeit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a567b06-8a39-49e9-a3a5-08460e618ee3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ~18mins\n",
    "\n",
    "# Execute CURATE without pop tau\n",
    "execute_CURATE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ed4fa-4011-43e5-a57f-b006098943b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CV\n",
    "five_fold_cross_val_results, five_fold_cross_val_results_summary = find_pop_tau_with_CV()\n",
    "execute_CURATE_and_update_pop_tau_results('CV', five_fold_cross_val_results_summary, five_fold_cross_val_results)\n",
    "\n",
    "# Perform LOOCV\n",
    "five_fold_cross_val_results, five_fold_cross_val_results_summary = find_pop_tau_with_LOOCV()\n",
    "execute_CURATE_and_update_pop_tau_results('LOOCV', five_fold_cross_val_results_summary, five_fold_cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a5e63c-c988-4ae4-9b87-64c997459796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = read_file_and_remove_unprocessed_pop_tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469d7827-d5ec-4031-bbc7-9ebcf839a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.copy()\n",
    "\n",
    "def run_LOOCV(method_list, method, linear_patient_list, quad_patient_list, dat):\n",
    "    \"\"\"...\"\"\"\n",
    "    # Define num of patients according to whether method is linear or quadratic\n",
    "    if 'L_' in method:\n",
    "        num_of_patients = len(linear_patient_list)\n",
    "        patient_list = linear_patient_list\n",
    "    else:\n",
    "        num_of_patients = len(quad_patient_list)\n",
    "        patient_list = quad_patient_list\n",
    "    \n",
    "    # Loop through experiments defined by number of patients\n",
    "    for j in range(num_of_patients):\n",
    "        \n",
    "        # Define test df\n",
    "        test_df = dat[(dat.method == method) & (dat.patient == patient_list[j])]\n",
    "        \n",
    "        # Define train df\n",
    "        train_patient_list = patient_list.copy()\n",
    "        train_patient_list.pop(j)\n",
    "        train_df = dat[(dat.method == method) & (dat.patient.isin(train_patient_list))]\n",
    "\n",
    "# # Shapiro test (result: some assume normality, some reject normality, thus use median)\n",
    "# df.groupby(['method', 'patient'])['abs_deviation'].apply(lambda x: stats.shapiro(x).pvalue < 0.05)\n",
    "\n",
    "def find_test_median_LOOCV(dat, method, patient_list, i):\n",
    "    \"\"\"Find median of test set\"\"\"\n",
    "    \n",
    "    # Define test df\n",
    "    test_df = dat[(dat.method == method) & (dat.patient == patient_list[i])]\n",
    "    \n",
    "    # Find test_median\n",
    "    test_median = test_df.abs_deviation.median()\n",
    "    \n",
    "    return test_median\n",
    "\n",
    "def find_train_median_LOOCV(dat, method, patient_list, i):\n",
    "    \"\"\"Find median of training set\"\"\"\n",
    "        \n",
    "    # Define train df\n",
    "    train_patient_list = patient_list.copy()\n",
    "    train_patient_list.pop(i)\n",
    "    train_df = dat[(dat.method == method) & (dat.patient.isin(train_patient_list))]\n",
    "\n",
    "    # Find train_median\n",
    "    train_median = train_df.abs_deviation.median()\n",
    "    \n",
    "    return train_median\n",
    "\n",
    "def num_patients_and_list(method, linear_patient_list, quad_patient_list):\n",
    "    \"\"\"Define num of patients according to whether method is linear or quadratic\"\"\"\n",
    "    \n",
    "    if 'L_' in method:\n",
    "        num_of_patients = len(linear_patient_list)\n",
    "        patient_list = linear_patient_list\n",
    "    else:\n",
    "        num_of_patients = len(quad_patient_list)\n",
    "        patient_list = quad_patient_list\n",
    "        \n",
    "    return num_of_patients, patient_list\n",
    "\n",
    "# Define lists\n",
    "linear_patient_list = dat[dat.method.str.contains('L_')].patient.unique().tolist()\n",
    "quad_patient_list = dat[dat.method.str.contains('Q_')].patient.unique().tolist()\n",
    "method_list = dat.method.unique().tolist()\n",
    "\n",
    "# Keep only useful columns in dataframe\n",
    "dat = dat[['method', 'patient', 'abs_deviation']]\n",
    "\n",
    "# Create output dataframes\n",
    "experiment_results_df = pd.DataFrame(columns=['method', 'experiment', 'train_median', 'test_median'])\n",
    "overall_results_df = pd.DataFrame(columns=['method', 'train (median)', 'test (median)'])\n",
    "\n",
    "exp_res_counter = 0\n",
    "overall_res_counter = 0\n",
    "\n",
    "for method in method_list:\n",
    "    \n",
    "    num_of_patients, patient_list = num_patients_and_list(method, linear_patient_list, quad_patient_list)\n",
    "    \n",
    "    for i in range(num_of_patients):\n",
    "        \n",
    "        train_median = find_train_median_LOOCV(dat, method, patient_list, i)\n",
    "        test_median = find_test_median_LOOCV(dat, method, patient_list, i)\n",
    "        \n",
    "        # print(f'experiment {i+1} | patient {patient_list[i]} | train_median {train_median} | test_median {test_median}')\n",
    "        \n",
    "        experiment_results_df.loc[exp_res_counter, 'experiment'] = i + 1\n",
    "        experiment_results_df.loc[exp_res_counter, 'method'] = method\n",
    "        experiment_results_df.loc[exp_res_counter, 'train_median'] = train_median\n",
    "        experiment_results_df.loc[exp_res_counter, 'test_median'] = test_median\n",
    "\n",
    "        exp_res_counter = exp_res_counter + 1\n",
    "        \n",
    "    # overall_results_df.loc[overall_res_counter, '']\n",
    "\n",
    "# # Shapiro test by method, on train_median and test_median (result: some normal)\n",
    "# train_median_shapiro = experiment_results_df.groupby('method')['train_median'].apply(lambda x: stats.shapiro(x).pvalue < 0.05)\n",
    "# test_median_shapiro = experiment_results_df.groupby('method')['test_median'].apply(lambda x: stats.shapiro(x).pvalue < 0.05)\n",
    "\n",
    "    \n",
    "#     overall_results = append_overall_results()\n",
    "\n",
    "# output_results_to_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddf160-3663-4646-963f-a37906183476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c728f2-0426-4d41-86ac-23891416c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can benefit SOC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa62ca-d28a-4e1a-b82b-f9a87bc99401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d36ec-f0c1-49cd-9ebb-a1b641bd3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Profile_Generation import *\n",
    "from plotting import *\n",
    "\n",
    "df = read_file_and_remove_unprocessed_pop_tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d4c4-c4b8-45d7-9b41-84c847fa43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = df.copy()\n",
    "\n",
    "# False negative/positive\n",
    "\n",
    "dat = origin_df[['patient', 'method', 'prediction', 'response']]\n",
    "\n",
    "# Create boolean, true when model predict wrong range\n",
    "for i in range(len(dat)):\n",
    "    # All False\n",
    "    dat.loc[i, 'wrong_range'] = False\n",
    "    # Unless condition 1: prediction within range, response outside range\n",
    "    if (dat.loc[i, 'prediction'] >= 8) and (dat.loc[i, 'prediction'] <= 10):\n",
    "        if (dat.loc[i, 'response'] > 10) or (dat.loc[i, 'response'] < 8):\n",
    "            dat.loc[i, 'wrong_range'] = True\n",
    "    # Unless condition 2: prediction outside range, response within range\n",
    "    elif (dat.loc[i, 'prediction'] > 10) or (dat.loc[i, 'prediction'] < 8):\n",
    "        if (dat.loc[i, 'response'] >= 8) and (dat.loc[i, 'response'] <= 10):\n",
    "            dat.loc[i, 'wrong_range'] = True\n",
    "\n",
    "dat = dat.groupby('method')['wrong_range'].apply(lambda x: x.sum() / x.count() * 100).reset_index()\n",
    "dat['source'] = 'CURATE'\n",
    "\n",
    "# Create another dataframe\n",
    "dat_physician = origin_df[['patient', 'method', 'prediction', 'response']]\n",
    "dat_physician = dat_physician[(dat_physician['method']=='L_Cum_wo_origin') | (dat_physician['method']=='Q_Cum_wo_origin')]\n",
    "dat_physician = dat_physician.reset_index(drop=True)\n",
    "\n",
    "# Create boolean, true if response is outside range\n",
    "for i in range(len(dat_physician)):\n",
    "    # Set boolean default as false\n",
    "    dat_physician.loc[i, 'wrong_range'] = False\n",
    "    # Create boolean as True if outside range\n",
    "    if (dat_physician.loc[i, 'response'] > 10) or (dat_physician.loc[i, 'response'] < 8):\n",
    "        dat_physician.loc[i, 'wrong_range'] = True\n",
    "\n",
    "dat_physician = dat_physician.groupby('method')['wrong_range'].apply(lambda x: x.sum() / x.count() * 100).reset_index()\n",
    "dat_physician['source'] = 'SOC'\n",
    "\n",
    "# Create dataframe with 2 stacked dataframes of dat_physician with pop tau column for both\n",
    "# pop tau and no pop tau\n",
    "dat_physician_1 = dat_physician.copy()\n",
    "dat_physician_1['pop_tau'] = 'pop tau'\n",
    "dat_physician_2 = dat_physician.copy()\n",
    "dat_physician_2['pop_tau'] = 'no pop tau'\n",
    "dat_SOC = pd.concat([dat_physician_1, dat_physician_2]).reset_index(drop=True)\n",
    "\n",
    "# Rename methods to linear and quadratic only\n",
    "for i in range(len(dat_SOC)):\n",
    "    if 'L_' in dat_SOC.method[i]:\n",
    "        dat_SOC.loc[i, 'method'] = 'L_SOC'\n",
    "    else:\n",
    "        dat_SOC.loc[i, 'method'] = 'Q_SOC'\n",
    "\n",
    "# Create pop tau column and rename methods without 'pop_tau'\n",
    "dat['pop_tau'] = \"\"\n",
    "for i in range(len(dat)):\n",
    "    if 'pop_tau' in dat.method[i]:\n",
    "        dat.loc[i, 'pop_tau'] = 'pop tau'\n",
    "        dat.loc[i, 'method'] = dat.method[i][:-8]\n",
    "    else:\n",
    "        dat.loc[i, 'pop_tau'] = 'no pop tau'\n",
    "        dat.loc[i, 'method'] = dat.method[i]\n",
    "\n",
    "combined_df = pd.concat([dat, dat_SOC]).reset_index()\n",
    "\n",
    "# # Boxplot\n",
    "# # sns.set(font_scale=2, rc={'figure.figsize':(15,10)})\n",
    "# sns.set_theme(font_scale=2)\n",
    "# sns.set_style('whitegrid')\n",
    "# ax = sns.boxplot(data=dat, x='method', y='wrong_range', hue='source', dodge=False)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "# ax.set_xlabel(None)\n",
    "# ax.set_ylabel('Wrong Range Predicted (%)')\n",
    "# ax.set_title('Wrong Range Predicted  (%)')\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.25,1))\n",
    "\n",
    "# Barplot\n",
    "sns.set(font_scale=1.4, rc={'figure.figsize':(5,40)})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "g = sns.catplot(data=combined_df, x='method', y='wrong_range', col='pop_tau',\n",
    "           kind='bar', hue='source', dodge=False)\n",
    "g.set(ylabel='No. of False Positive/\\nFalse Negative Predictions (%)',\n",
    "     xlabel=None)\n",
    "g.set_xticklabels(rotation=90)\n",
    "# plt.ylabels('No. of False Positive/False Negative Predictions (%)')\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "plt.savefig('false_pos_neg.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e4711-7289-44a3-a6e0-3dd7f5d59e5b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('GOOD OUTPUT DATA\\output (with pop tau by LOOCV).xlsx', sheet_name='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502029ea-23f4-4c6d-a7af-498697aeab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.copy()\n",
    "# Keep all methods in dataframe except strictly tau methods (contains 'tau' but does not contain 'pop')\n",
    "method_list = dat.method.unique().tolist()\n",
    "exclude_method_list = [x for x in method_list if (('tau' in x) and ('pop' not in x))]\n",
    "method_list = [x for x in method_list if x not in exclude_method_list]\n",
    "dat = dat[dat.method.isin(method_list)]\n",
    "dat = dat.reset_index(drop=True)\n",
    "\n",
    "num_pred_linear = dat[dat.method=='L_Cum_wo_origin'].prediction.count()\n",
    "num_pred_quad = dat[dat.method=='Q_Cum_wo_origin'].prediction.count()\n",
    "\n",
    "print(f'num_pred_linear {num_pred_linear} | num_pred_quad {num_pred_quad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fca35-4c50-4da8-9cd8-4d9c966c1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.copy()\n",
    "\n",
    "# Keep all methods in dataframe except strictly tau methods (contains 'tau' but does not contain 'pop')\n",
    "method_list = dat.method.unique().tolist()\n",
    "exclude_method_list = [x for x in method_list if (('tau' in x) and ('pop' not in x))]\n",
    "method_list = [x for x in method_list if x not in exclude_method_list]\n",
    "dat = dat[dat.method.isin(method_list)]\n",
    "dat = dat.reset_index(drop=True)\n",
    "\n",
    "# Create column for cond_1 where both predicted and observed values are out-of-range\n",
    "dat['cond_1'] = ((dat.prediction < 8) | (dat.prediction > 10)) & ((dat.response < 8) | (dat.response > 10))\n",
    "\n",
    "# Create column for cond_2 where prediction error is between -3 and +1\n",
    "dat['cond_2'] = (dat.deviation > -3) & (dat.deviation < 1)\n",
    "\n",
    "# Interpolate for 8, 9, 10mg\n",
    "for i in range(len(dat)):\n",
    "    # Create function\n",
    "    coeff = dat.loc[i, 'coeff_2x':'coeff_0x'].apply(float).to_numpy()\n",
    "    coeff = coeff[~np.isnan(coeff)]\n",
    "    p = np.poly1d(coeff)\n",
    "    x = np.linspace(0, 9)\n",
    "    y = p(x)\n",
    "    order = y.argsort()\n",
    "    y = y[order]\n",
    "    x = x[order]\n",
    "\n",
    "    dat.loc[i, 'interpolated_dose_8'] = np.interp(8, y, x).tolist()\n",
    "    dat.loc[i, 'interpolated_dose_9'] = np.interp(9, y, x).tolist()\n",
    "    dat.loc[i, 'interpolated_dose_10'] = np.interp(10, y, x).tolist()\n",
    "\n",
    "# dat[['coeff_2x', 'coeff_1x', 'coeff_0x', 'interpolated_dose_8','interpolated_dose_9','interpolated_dose_10']].describe()\n",
    "# dat[['prediction', 'response', 'deviation', 'cond_1', 'cond_2']]\n",
    "# dat\n",
    "'interpolated_dose_8'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e2f5a-24b7-480f-90c8-a106c8e9120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.iscomplex(dat.interpolated_dose_10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e355a-3e2a-42d1-8fe1-7f9285a255d7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = 2.881250\n",
    "b = -0.121875\n",
    "# c = -16.252151\n",
    "\n",
    "x = 3.513015\n",
    "a*x + b\n",
    "\n",
    "# a*np.square(x) + b*x + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4062ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_excel('GOOD OUTPUT DATA\\output (with pop tau by LOOCV).xlsx', sheet_name='result')\n",
    "\n",
    "# Keep all methods in dataframe except strictly tau methods (contains 'tau' but does not contain 'pop')\n",
    "method_list = dat.method.unique().tolist()\n",
    "exclude_method_list = [x for x in method_list if (('tau' in x) and ('pop' not in x))]\n",
    "method_list = [x for x in method_list if x not in exclude_method_list]\n",
    "dat = dat[dat.method.isin(method_list)]\n",
    "dat = dat.reset_index(drop=True)\n",
    "\n",
    "# Find RMSE by method\n",
    "def rmse(dat):\n",
    "    rmse = mean_squared_error(dat.response, dat.prediction, squared=False)\n",
    "    return pd.Series(dict(rmse=rmse))\n",
    "\n",
    "dat = dat.groupby('method').apply(rmse).reset_index()\n",
    "\n",
    "# Create pop tau column and remove 'pop_tau' from method name\n",
    "dat['pop_tau'] = \"\"\n",
    "dat['OG_method'] = \"\"\n",
    "for i in range(len(dat)):\n",
    "    if 'pop_tau' in dat.method[i]:\n",
    "        dat.loc[i, 'pop_tau'] = 'pop tau'\n",
    "        dat.loc[i, 'OG_method'] = dat.loc[i, 'method'][:-8]\n",
    "    else: \n",
    "        dat.loc[i, 'pop_tau'] = 'no pop tau'\n",
    "        dat.loc[i, 'OG_method'] = dat.loc[i, 'method']\n",
    "\n",
    "# Line plot of RMSE for pop tau and non pop tau\n",
    "plt.figure(figsize=(15,10))\n",
    "f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# sns.lineplot(data=dat, x='OG_method', y='rmse', hue='pop_tau', marker='o', ax=ax)\n",
    "# sns.lineplot(data=dat, x='OG_method', y='rmse', hue='pop_tau', marker='o', ax=ax2)\n",
    "\n",
    "ax = sns.catplot(data=dat, x='OG_method', y='rmse', hue='pop_tau', ax=ax, kind='bar')\n",
    "ax2 = sns.catplot(data=dat, x='OG_method', y='rmse', hue='pop_tau', ax=ax2, kind='bar')\n",
    "\n",
    "ax2.set_ylim([min(dat.rmse), 12])\n",
    "ax.set_ylim([np.exp(12), max(dat.rmse)+np.exp(12)])\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "d = .015  # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass to plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "ax.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
    "\n",
    "ax.set_ylabel(None)\n",
    "ax2.set_ylabel('RMSE', loc='top')\n",
    "ax2.set_xlabel(None)\n",
    "ax2.get_legend().remove()\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Save\n",
    "plt.savefig('RMSE.png', bbox_inches='tight', dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a45b75-2a50-40af-bded-2c8f10903e89",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# How are the predictions different, between different half-lives, for each method compared to without tau?\n",
    "# Plot prediction vs prediction day, for each patient, colored by tau with different half-lives vs non-tau\n",
    "\n",
    "dat = result_df.copy()\n",
    "dat = dat[['prediction', 'pred_day', 'half_life', 'method', 'patient', 'deviation']]\n",
    "patient_list = dat.patient.unique()\n",
    "method_list = dat.method.unique()\n",
    "dat = dat[dat.patient == patient_list[6]]\n",
    "dat.half_life = dat.half_life.fillna(0)\n",
    "# L_Cum_origin_dp_tau\n",
    "palette = sns.color_palette(\"rocket_r\", n_colors=len(dat.half_life.unique()))\n",
    "# a = np.arange(3.5, 41.5, 1)\n",
    "# dat.half_life.unique()\n",
    "sns.lineplot(data=dat[dat.method.str.contains(\"L_RW_origin_dp\")], \n",
    "             x=\"pred_day\", y=\"deviation\", hue=\"half_life\", \n",
    "             palette=palette, ci=None)\n",
    "plt.legend(bbox_to_anchor=(1.25,1), loc='upper right')\n",
    "# plt.plot(data=dat[dat.method == \"L_Cum_origin_dp_tau\"], \n",
    "#          x=\"pred_day\", y=\"prediction\", color=\"half_life\".map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996fe88-eeda-4d36-85c3-8fc922fc6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = result_df.copy()\n",
    "dat = dat[['deviation', 'method', 'patient', 'pred_day', 'response', 'prediction', 'half_life']]\n",
    "dat['half_life'] = dat['half_life'].fillna('')\n",
    "dat = dat.loc[(dat.method == 'Q_Cum_origin_dp_tau') | (dat.method == 'Q_Cum_origin_dp')]\n",
    "dat['new_method'] = \"\"\n",
    "for i in range(len(dat)):\n",
    "    dat['new_method'].iloc[i] = dat['method'].iloc[i] + '_' + str(dat['half_life'].iloc[i])\n",
    "    # print(dat['method'].iloc[i])\n",
    "plot = sns.lineplot(data=dat, x=\"patient\", y=\"deviation\", hue=\"new_method\", ci=None, legend=False)\n",
    "plot = sns.lineplot(data=dat.loc[dat.method=='Q_Cum_origin_dp_ '], x=\"patient\", y=\"deviation\", color='b', ci=None, legend=False)\n",
    "# dat.head()\n",
    "\n",
    "# sns.lineplot(data=dat.loc[dat.patient==84], x=\"pred_day\", y=\"deviation\", hue=\"method\")\n",
    "\n",
    "# dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2120d-c413-46ef-8be9-eeed043c086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "# perc_days_within_target_tac(result_df)\n",
    "# perc_days_outside_target_tac(result_df)\n",
    "# median_perc_within_acc_dev(result_df)\n",
    "# can_benefit(result_df)\n",
    "# modified_TTR(result_df)\n",
    "# wrong_range(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e4ecf-0dcb-4752-b2d7-7dd3d23736e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "d = {'dose': [0.5, 1, 1.5, 1.5, 3, 3], 'response': [2.4, 2.8, 3.2, 3.1, 7.9, 10]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "# Calculate weight\n",
    "j = 0\n",
    "decay_weight = []\n",
    "for i in range(len(df)):\n",
    "    decay_weight.append(math.exp(-(24*(i))/(12/np.log(2))))\n",
    "\n",
    "# Fit model\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "X = np.array(df.dose).reshape(-1, 1)\n",
    "y = np.array(df.response)\n",
    "X = poly_reg.fit_transform(X)\n",
    "result = LinearRegression(fit_intercept=False).fit(X, y, decay_weight)\n",
    "result.coef_\n",
    "# new = 3\n",
    "# prediction = result.predict(poly_reg.fit_transform([[new]]))[0]\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c05864-125d-42c8-a46c-5bdf99af7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(3).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ef72a-2792-4af4-8594-6d7946b1312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(columns=['col1','col2'])\n",
    "a = a[0:0]\n",
    "a.loc[2, :] = [1, 2]\n",
    "\n",
    "b = pd.DataFrame(columns=['col1','col2'])\n",
    "b = b[0:0]\n",
    "b.loc[0, :] = [1, 2]\n",
    "b.loc[1, :] = [1, 2]\n",
    "\n",
    "pd.concat([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ae9b4-7742-4b60-90ff-5737d3a7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = \"\"\n",
    "if hello:\n",
    "    print('not empty')\n",
    "else: print('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841be05-3fa2-472e-a82d-876db948fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['a','b']\n",
    "list_of_series = [pd.Series([1,2],index=cols), pd.Series([3,4],index=cols)]\n",
    "df = pd.DataFrame(list_of_series, columns=cols)\n",
    "df = pd.DataFrame(columns=cols)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
